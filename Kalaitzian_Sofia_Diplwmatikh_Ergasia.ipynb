{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efe687db",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01beea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import ast\n",
    "import time\n",
    "import numpy as np\n",
    "import csv\n",
    "import boto3 \n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from numpy import absolute\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d880e32b",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a5bf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'BBC_1000_new.xlsx')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c11c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform links in column 'SiteLink' to be clickable \n",
    "def make_clickable(val):\n",
    "    # target _blank to open new window\n",
    "    return '<a target=\"_blank\" href=\"{}\">{}</a>'.format(val, val)\n",
    "\n",
    "df.style.format({'SiteLink': make_clickable})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770868b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image pre-processing (delete pictures that have no sense with the analysis and check for duplicates in Link Text column)\n",
    "\n",
    "df1 = df.head(1000)\n",
    "list1 = df1['SiteLink'].tolist()\n",
    "\n",
    "l1 = []\n",
    "for site in list1:\n",
    "    response = requests.get(site)\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    headlines = doc.find_all('img')\n",
    "    l1 += [headlines[0]['src']]\n",
    "\n",
    "counter = -1\n",
    "link_name = []\n",
    "for img in l1:\n",
    "    \n",
    "    counter = counter + 1    \n",
    "    # We can split the file based upon / and extract the last split within the python list below:\n",
    "    file_name = img.split('/')[-1]\n",
    "    file_name2 = file_name.split('.')[0]\n",
    "    file_name2 = \"_\" + str(counter) + \".\"\n",
    "    file_name = file_name2 + file_name.split('.')[-1]\n",
    "    print(f\"This is the file name: {file_name}\")\n",
    "    link_name.append(file_name)\n",
    "    \n",
    "    # Now let's send a request to the image URL:\n",
    "    r = requests.get(img, stream=True)\n",
    "    \n",
    "    # We can check that the status code is 200 before doing anything else:\n",
    "    if r.status_code == 200:\n",
    "        # This command below will allow us to write the data to a file as binary:\n",
    "        with open(file_name, 'wb') as f:\n",
    "            for chunk in r:\n",
    "                f.write(chunk)\n",
    "    else:\n",
    "        # We will write all of the images back to the broken_images list:\n",
    "        broken_images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d512ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a photo name description to be joined with the main table\n",
    "imgurl = pd.DataFrame(l1)\n",
    "imgurl = imgurl.rename(columns={0: 'Link_Name'})\n",
    "imgurl.index += 1\n",
    "\n",
    "imgurl2 = pd.DataFrame(link_name)\n",
    "imgurl2 = imgurl2.rename(columns={0: 'Photo_Name'})\n",
    "imgurl2.index += 1\n",
    "\n",
    "imgurl['Photo_Name'] = imgurl2['Photo_Name']\n",
    "idx = 0\n",
    "imgurl.insert(idx, 'ImageCode', value=np.arange(len(imgurl)))\n",
    "\n",
    "df_final = df.head(1000)\n",
    "df_final = pd.merge(df_final,imgurl[[\"ImageCode\",\"Photo_Name\"]],on='ImageCode')\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a97c7fb",
   "metadata": {},
   "source": [
    "# AWS Rekognition Object/Scene Detection API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c40dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Paths\n",
    "# Path to where your want to save the resulting labels\n",
    "rekog_results_dir = 'C:/Users/sofia/Desktop/ΔΙΠΛΩΜΑΤΙΚΗ/results/'\n",
    "# Path to where your images are\n",
    "rekog_images_dir = 'C:/Users/sofia/Desktop/ΔΙΠΛΩΜΑΤΙΚΗ/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d8231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Connect to Rekognition API\n",
    "# Read in your personal keys\n",
    "personal_access_key = \"\"\n",
    "secret_access_key = \"\"\n",
    "\n",
    "# Initialize the boto client to access the Rekogniton api\n",
    "client=boto3.client('rekognition','us-east-1', # or choose the best region for your work, \n",
    "                                               # e.g. the location of your S3 bucket if using that method to store images\n",
    "                    aws_access_key_id = personal_access_key, \n",
    "                    aws_secret_access_key = secret_access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f8ce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Create a list of images to run through the API\n",
    "# Make a list of all the images in the rekog_data_dir you created\n",
    "local_images = os.listdir(rekog_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca7196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#local_images[:200]\n",
    "#local_images[200:400]\n",
    "#local_images[400:600]\n",
    "#local_images[600:800]\n",
    "#local_images[800:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae7c736",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Run each image through the API and store the results\n",
    "##### Detect labels\n",
    "### Insert 200 pictures each time and change the path of the excel below\n",
    "holder_labels = []\n",
    "\n",
    "for imageFile in local_images[800:1000]: # change here each time the number of images to be inserted (200 pictures each time)\n",
    "    with open(rekog_images_dir + imageFile, 'rb') as image:\n",
    "            response = client.detect_labels(Image={'Bytes': image.read()})\n",
    "    \n",
    "    print('Detected labels for ' + imageFile)\n",
    "    \n",
    "    ## If no labels detected, still save the info:\n",
    "    if len(response['Labels']) == 0:\n",
    "        print (\"No Labels Detected\")\n",
    "        temp_dict = {}\n",
    "        temp_dict[\"image_id\"] = imageFile\n",
    "        temp_dict[\"full_detect_labels_response\"] = response\n",
    "        temp_dict[\"label_num\"] = ''\n",
    "        temp_dict[\"label_str\"] = ''\n",
    "        temp_dict[\"label_conf\"] = ''\n",
    "        holder_labels.append(temp_dict)   \n",
    "    \n",
    "    else:\n",
    "        \n",
    "        label_counter = 1\n",
    "        \n",
    "        for label in response['Labels']:\n",
    "            print (label['Name'] + ' : ' + str(label['Confidence']))\n",
    "            temp_dict = {}\n",
    "            temp_dict[\"image_id\"] = imageFile\n",
    "            temp_dict[\"full_detect_labels_response\"] = response\n",
    "            temp_dict[\"label_num\"] = label_counter\n",
    "            temp_dict[\"label_str\"] = label['Name']\n",
    "            temp_dict[\"label_conf\"] = label['Confidence']\n",
    "            label_counter +=1 # update for the next label\n",
    "            holder_labels.append(temp_dict)\n",
    "            \n",
    "len(holder_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394fa112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the results to a csv\n",
    "with open(rekog_results_dir + 'awsrekognition_detect_labels_5.csv', 'w', newline = '') as csvfile:\n",
    "    fieldnames = ['image_id', 'full_detect_labels_response',\n",
    "                  'label_num', 'label_str',\n",
    "                  'label_conf'\n",
    "                  ]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader() \n",
    "    for entry in holder_labels:\n",
    "        writer.writerow(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f167e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final dataframe\n",
    "detect_labels_df1 = pd.read_csv('C:/Users/sofia/Desktop/ΔΙΠΛΩΜΑΤΙΚΗ/results/awsrekognition_detect_labels_1.csv')\n",
    "detect_labels_df2 = pd.read_csv('C:/Users/sofia/Desktop/ΔΙΠΛΩΜΑΤΙΚΗ/results/awsrekognition_detect_labels_2.csv')\n",
    "detect_labels_df3 = pd.read_csv('C:/Users/sofia/Desktop/ΔΙΠΛΩΜΑΤΙΚΗ/results/awsrekognition_detect_labels_3.csv')\n",
    "detect_labels_df4 = pd.read_csv('C:/Users/sofia/Desktop/ΔΙΠΛΩΜΑΤΙΚΗ/results/awsrekognition_detect_labels_4.csv')\n",
    "detect_labels_df5 = pd.read_csv('C:/Users/sofia/Desktop/ΔΙΠΛΩΜΑΤΙΚΗ/results/awsrekognition_detect_labels_5.csv')\n",
    "detect_labels_df = pd.concat([detect_labels_df1, detect_labels_df2, detect_labels_df3, detect_labels_df4, detect_labels_df5], ignore_index=True)\n",
    "\n",
    "df_final.rename(columns = {'Photo_Name':'image_id'}, inplace = True)\n",
    "df_final = pd.merge(df_final,detect_labels_df,on='image_id',how='right')\n",
    "df_final.to_excel(r'BBC_final_df.xlsx')\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c443873d",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00420d93",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a74cca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'BBC_1000_new_v2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c9ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Post_Created_Hour'] = df['Post Created Time'].str[:2]\n",
    "df['Post_Created_Hour']=pd.to_numeric(df.Post_Created_Hour)\n",
    "df['Link_Text_Count'] = df['Link Text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04ca46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers\n",
    "df.drop(df[df.Likes > 40000].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a112bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove variables not important for our analysis in this step\n",
    "df.drop(['Post Created', 'Post Created Date', 'Post Created Time', 'FacebookURL', 'Message', 'SiteLink', 'Link Text', 'ImageCode'], axis=1, inplace=True)\n",
    "# arrange columns\n",
    "data = df[['Likes', 'Likes at Posting', 'Followers at Posting', 'Total Interactions', 'Comments', 'Shares', 'Love', 'Wow', 'Haha', 'Sad', 'Angry', 'Care', 'Post_Created_Hour', 'Link_Text_Count', 'Animal', 'Clothing', 'Military', 'Nature', 'Person', 'Vehicle', 'Other', 'Overperforming Score ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300dc304",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of missing values inside the dataset: \", data.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b0e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Likes'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d5bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aaedba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(grid=False, figsize=(15,12), color='#86bf91', zorder=2, rwidth=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6781190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Pearson Correlation\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(17,10))\n",
    "cor = data.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c475278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation with output variable\n",
    "# Remove variables correlated with Y and between them > 80% (Remove Total Interactions, Love, Followers at Posting)\n",
    "cor_target = abs(cor[\"Likes\"])\n",
    "#Selecting highly correlated features\n",
    "relevant_features = cor_target[cor_target>0.7]\n",
    "relevant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40915fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove variables not important for our analysis and variables correlated > 0.7 with the target variable\n",
    "data.drop(['Likes at Posting', 'Followers at Posting', 'Total Interactions', 'Comments', 'Shares', 'Love', 'Overperforming Score '], axis=1, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8679c897",
   "metadata": {},
   "source": [
    "### 1st Modeling Part - Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5003de",
   "metadata": {},
   "source": [
    "Our purpose is to predict the number of likes of a Facebook post, based on the number of attributes that we have previously observed and the different number of extra features we created after the Image Rekognition implementation using the Clarifai portal. To do that we will use a number of different Regression models, which can be used to predict numerical values, not just classes, in order to rectify which one of these yields the best results for our approach. The steps that we followed were:\n",
    " * **`Step_1:`** Split the data into training and test sets\n",
    " * **`Step_2:`** Train a number of different regression models (Linear, Random Forest, Decision Tree, XGBoost)\n",
    " * **`Step_3:`** Fit the different regression models to the training data\n",
    " * **`Step_4:`** Make the necessary predictions\n",
    " * **`Step_5:`** Use Grid Search, an Evaluator for our initial predictions and Cross Validation in order to improve our model and find the best model\n",
    " * **`Step_6:`** Calculate a number of different metrics (R2, MAE, MSE, RMSE) on test data and print a table showing the basic statistics of the target variable, in order to see if the predictions were worthwhile or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bf5d72",
   "metadata": {},
   "source": [
    "#### Split dataset into Train/Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop('Likes', axis=1)\n",
    "Y = pd.DataFrame(data.Likes)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "# X_train (70% from all features without the target variable)\n",
    "# Y_train (70% including only the target variable)\n",
    "# X_test (30% from all features without the target variable)\n",
    "# Y_test (30% including only the target variable -> the numbers that we want to see how much close we are)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2737994f",
   "metadata": {},
   "source": [
    "#### Perform Cross Validation/Grid Search for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a75a133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The user can choose one of the below models\n",
    "a = LinearRegression()\n",
    "b = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
    "c = DecisionTreeRegressor(max_depth=2)\n",
    "\n",
    "model = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e095c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step-1: create a cross-validation scheme\n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{'n_features_to_select': list(range(1, 9))}]\n",
    "\n",
    "# step-3: perform grid search and specify model\n",
    "model.fit(X_train, Y_train)\n",
    "rfe = RFE(model)             \n",
    "\n",
    "# 3.2 call GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = rfe, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'r2', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train, Y_train)  \n",
    "\n",
    "# cross-validation results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "\n",
    "# final model (FIX THE n_features_optimal FOR EACH MODEL)\n",
    "n_features_optimal = 8\n",
    "model.fit(X_train, Y_train)\n",
    "rfe = RFE(model, n_features_to_select=n_features_optimal)             \n",
    "rfe = rfe.fit(X_train, Y_train)\n",
    "\n",
    "# predict prices of X_test/X_train\n",
    "Y_pred_test = model.predict(X_test)\n",
    "Y_pred_train = model.predict(X_train)\n",
    "\n",
    "# metrics results (na deiksw poia features exoun to antistoixo coeff)\n",
    "try:\n",
    "    print('Coefficients:', model.coef_)\n",
    "    #print('Intercept:', model.intercept_)\n",
    "    print('Mean absolute error (MAE) Test: %.2f'\n",
    "          % mean_absolute_error(Y_test, Y_pred_test, sample_weight=None, multioutput='uniform_average')) \n",
    "    print('Mean absolute error (MAE) Train: %.2f'\n",
    "          % mean_absolute_error(Y_train, Y_pred_train, sample_weight=None, multioutput='uniform_average')) \n",
    "    print('Mean squared error (MSE) Test: %.2f'\n",
    "          % mean_squared_error(Y_test, Y_pred_test)) \n",
    "    print('Mean squared error (MSE) Train: %.2f'\n",
    "          % mean_squared_error(Y_train, Y_pred_train)) \n",
    "    print('Root mean squared error (RMSE) Test: %.2f'\n",
    "          % mean_squared_error(Y_test, Y_pred_test, squared=False)) \n",
    "    print('Root mean squared error (RMSE) Train: %.2f'\n",
    "          % mean_squared_error(Y_train, Y_pred_train, squared=False))\n",
    "    print('Coefficient of determination (R^2) Test: %.2f'\n",
    "          % r2_score(Y_test, Y_pred_test))\n",
    "    print('Coefficient of determination (R^2) Train: %.2f'\n",
    "          % r2_score(Y_train, Y_pred_train))\n",
    "except:\n",
    "    print('Coefficients:', model.feature_importances_)\n",
    "    #print('Intercept:', model.intercept_)\n",
    "    print('Mean Absolute Error (MAE) Test:', metrics.mean_absolute_error(Y_test, Y_pred_test))\n",
    "    print('Mean Absolute Error (MAE) Train:', metrics.mean_absolute_error(Y_train, Y_pred_train))\n",
    "    print('Mean Squared Error (MSE) Test:', metrics.mean_squared_error(Y_test, Y_pred_test))  \n",
    "    print('Mean Squared Error (MSE) Train:', metrics.mean_squared_error(Y_train, Y_pred_train))  \n",
    "    print('Root Mean Squared Error (RMSE) Test:', np.sqrt(metrics.mean_squared_error(Y_test, Y_pred_test)))\n",
    "    print('Root Mean Squared Error (RMSE) Train:', np.sqrt(metrics.mean_squared_error(Y_train, Y_pred_train)))\n",
    "    print('Coefficient of determination (R^2) Test: %.2f' % r2_score(Y_test, Y_pred_test))\n",
    "    print('Coefficient of determination (R^2) Train: %.2f' % r2_score(Y_train, Y_pred_train))\n",
    "    \n",
    "\n",
    "# plotting cv results\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_test_score\"])\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_train_score\"])\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('r-squared')\n",
    "plt.title(\"Optimal Number of Features\")\n",
    "plt.legend(['test score', 'train score'], loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b424deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_df = Y_test\n",
    "actual_df = actual_df.rename(columns={\"Likes\": \"Actual Likes\"})\n",
    "actual_df = actual_df.reset_index(drop=True)\n",
    "predicted_df = pd.DataFrame(Y_pred_test)\n",
    "predicted_df = predicted_df.rename(columns={0: \"Predicted Likes\"})\n",
    "\n",
    "actual_predicted_df = pd.concat([actual_df, predicted_df], axis=1)\n",
    "\n",
    "# Comment each time the model that is not used:\n",
    "# linear_regression_df = actual_predicted_df\n",
    "# linear_regression_df['Model'] = 'Linear Regression'\n",
    "# rf_regression_df = actual_predicted_df\n",
    "# rf_regression_df['Model'] = 'Random Forest Regression'\n",
    "# dt_regression_df = actual_predicted_df\n",
    "# dt_regression_df['Model'] = 'Decision Tree Regression'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280ff3ce",
   "metadata": {},
   "source": [
    "#### XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84158ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(n_estimators=1000, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7d9607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the Algorithm\n",
    "from sklearn import metrics\n",
    "print('Coefficients:', model.feature_importances_)\n",
    "print('Mean Absolute Error (MAE) Test:', metrics.mean_absolute_error(Y_test, Y_pred_test))  \n",
    "print('Mean Absolute Error (MAE) Train:', metrics.mean_absolute_error(Y_train, Y_pred_train)) \n",
    "print('Mean Squared Error (MSE) Test:', metrics.mean_squared_error(Y_test, Y_pred_test))  \n",
    "print('Mean Absolute Error (MSE) Train:', metrics.mean_squared_error(Y_train, Y_pred_train)) \n",
    "print('Root Mean Squared Error (RMSE) Test:', np.sqrt(metrics.mean_squared_error(Y_test, Y_pred_test)))\n",
    "print('Root Mean Squared Error (RMSE) Train:', np.sqrt(metrics.mean_squared_error(Y_train, Y_pred_train)))\n",
    "print('Coefficient of determination (R^2) Test: %.2f' % r2_score(Y_test, Y_pred_test))\n",
    "print('Coefficient of determination (R^2) Train: %.2f' % r2_score(Y_train, Y_pred_train))\n",
    "\n",
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X_train, Y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# force scores to be positive\n",
    "scores = absolute(scores)\n",
    "print('Mean MAE: %.3f (%.3f)' % (scores.mean(), scores.std()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ff3e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_df = Y_test\n",
    "actual_df = actual_df.rename(columns={\"Likes\": \"Actual Likes\"})\n",
    "actual_df = actual_df.reset_index(drop=True)\n",
    "predicted_df = pd.DataFrame(Y_pred_test)\n",
    "predicted_df = predicted_df.rename(columns={0: \"Predicted Likes\"})\n",
    "\n",
    "actual_predicted_df = pd.concat([actual_df, predicted_df], axis=1)\n",
    "xgb_regression_df = actual_predicted_df\n",
    "xgb_regression_df['Model'] = 'XGBoost Regression'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa7e7e6",
   "metadata": {},
   "source": [
    "#### Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bc3fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a box plot from the value ranges (predicted/actual) from all the models (Y_pred - Y_test)\n",
    "\n",
    "dfs = [linear_regression_df, rf_regression_df, dt_regression_df, xgb_regression_df]\n",
    "actual_predicted_df2 = pd.concat(dfs)\n",
    "actual_predicted_df2 = actual_predicted_df2.reset_index(drop=True)\n",
    "actual_predicted_df2[\"Actual_Predicted_Differences\"] = actual_predicted_df2[\"Predicted Likes\"] - actual_predicted_df2[\"Actual Likes\"]\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(rc={'figure.figsize':(12,9)})\n",
    "sns.boxplot(x = 'Model', y = 'Actual_Predicted_Differences', data = actual_predicted_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef25ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a graph with the predicted vs actual values of the best model\n",
    "rf_regression_df2 = rf_regression_df.rename(columns={\"Predicted Likes\": \"Predicted_Likes\", \"Actual Likes\": \"Actual_Likes\"})\n",
    "Actual_Likes = rf_regression_df2[\"Actual_Likes\"]\n",
    "Predicted_Likes = rf_regression_df2[\"Predicted_Likes\"]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(Actual_Likes, Predicted_Likes, c='crimson')\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "\n",
    "p1 = max(max(Predicted_Likes), max(Actual_Likes))\n",
    "p2 = min(min(Predicted_Likes), min(Actual_Likes))\n",
    "plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "plt.xlabel('Actual Likes', fontsize=15)\n",
    "plt.ylabel('Predicted Likes', fontsize=15)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7a3e31",
   "metadata": {},
   "source": [
    "### 2nd Modeling Part - Classification Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09575ba4",
   "metadata": {},
   "source": [
    "Our purpose is to predict if a Facebook post is succesful or not, based on the number of attributes that we have previously observed and the different number of extra features we created after the Image Rekognition implementation using the Clarifai portal. To do that we will use a number of different Classification models, which can be used to predict classes, in order to rectify which one of these yields the best results for our approach. The steps that we followed were:\n",
    " * **`Step_1:`** Create 2 buckets of High/Low number of Likes based on the avg number of Likes\n",
    " * **`Step_2:`** Split the data into training and test sets\n",
    " * **`Step_3:`** Train a number of different classification models (Logistic Regression, Random Forest Classifier, Decision Tree Classifier)\n",
    " * **`Step_4:`** Use Cross Validation in order to improve our models and find the best model\n",
    " * **`Step_5:`** Fit the different classification models to the training data\n",
    " * **`Step_6:`** Make the necessary predictions\n",
    " * **`Step_7:`** Calculate a number of different metrics (Accuracy, Precision, Specificity, Sensitivity, AUC) on test data and print the corresponding classification report of the best model, in order to see if the predictions were worthwhile or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b72f29",
   "metadata": {},
   "source": [
    "#### Split Likes on High/Low buckets based on the avg number of Likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11293c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_of_likes = data[\"Likes\"].mean()\n",
    "\n",
    "def f(row):\n",
    "    if row['Likes'] > mean_of_likes:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "data['Likes_Grouped'] = data.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1a3326",
   "metadata": {},
   "source": [
    "#### Split dataset into Train/Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e2ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.drop('Likes', axis=1)\n",
    "array = data2.values\n",
    "\n",
    "# Features: without the target variable\n",
    "X = array[:,0:-1]\n",
    "\n",
    "# Target variable: 'Likes_Grouped'\n",
    "Y = array[:,-1]\n",
    "\n",
    "# 30% of the data will be used for testing\n",
    "test_size= 0.30\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X, Y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13a68ed",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b280127",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('DT', DecisionTreeClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf9feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_c = []\n",
    "names_c = []\n",
    "\n",
    "for name, model in models:\n",
    "    # define how to split off validation data ('kfold' how many folds)\n",
    "    #kfold = KFold(n_splits=10, random_state=seed)    \n",
    "    kfold = KFold(n_splits=10)\n",
    "    # train the model\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')    \n",
    "    results_c.append(cv_results)\n",
    "    names_c.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b600a720",
   "metadata": {},
   "source": [
    "#### Results of Models' Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc102ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfomance of Classification Algorithms Boxplots\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Perfomance of Classification Algorithms')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results_c)\n",
    "ax.set_xticklabels(names_c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a2654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy, Sensitivity and Specificity scores of all models\n",
    "\n",
    "# Fit the models\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, Y_train)\n",
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train, Y_train)\n",
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(X_train, Y_train)\n",
    "\n",
    "# Make the predictions\n",
    "predictions_LR = LR.predict(X_test)\n",
    "predictions_RF = RF.predict(X_test)\n",
    "predictions_DT = DT.predict(X_test)\n",
    "\n",
    "# Accuracy Scores\n",
    "print(\"Accuracy Scores\")\n",
    "print(\"LR:\", accuracy_score(Y_test, predictions_LR))\n",
    "print(\"RF:\", accuracy_score(Y_test, predictions_RF))\n",
    "print(\"DT:\", accuracy_score(Y_test, predictions_DT))\n",
    "print(\"\")\n",
    "\n",
    "# Precision Scores\n",
    "print(\"Precision Scores\")\n",
    "print(\"LR:\", precision_score(Y_test, predictions_LR))\n",
    "print(\"RF:\", precision_score(Y_test, predictions_RF))\n",
    "print(\"DT:\", precision_score(Y_test, predictions_DT))\n",
    "print(\"\")\n",
    "\n",
    "# # Specificity Scores\n",
    "print(\"Specificity Scores\")\n",
    "tn_LR, fp_LR, fn_LR, tp_LR = confusion_matrix(Y_test, predictions_LR).ravel()\n",
    "tn_RF, fp_RF, fn_RF, tp_RF = confusion_matrix(Y_test, predictions_RF).ravel()\n",
    "tn_DT, fp_DT, fn_DT, tp_DT = confusion_matrix(Y_test, predictions_DT).ravel()\n",
    "print(\"LR:\", tn_LR / (tn_LR+fp_LR))\n",
    "print(\"RF:\", tn_RF / (tn_RF+fp_RF))\n",
    "print(\"DT:\", tn_DT / (tn_DT+fp_DT))\n",
    "print(\"\")\n",
    "\n",
    "# Sensitivity Scores\n",
    "print(\"Recall Scores\")\n",
    "print(\"LR:\", recall_score(Y_test, predictions_LR))\n",
    "print(\"RF:\", recall_score(Y_test, predictions_RF))\n",
    "print(\"DT:\", recall_score(Y_test, predictions_DT))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70baeff",
   "metadata": {},
   "source": [
    "### Validation results of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3a4cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix and Classification Report\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score  \n",
    "conf_mat = confusion_matrix(Y_test, predictions_RF) #confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "            xticklabels=['0', '1'], \n",
    "            yticklabels=['0', '1'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix of the Random Forest Classifier')\n",
    "plt.show()\n",
    "print(classification_report(Y_test,predictions_RF)) #classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3931c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC Curve\n",
    "from sklearn import metrics\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_test,  predictions_RF)\n",
    "auc = metrics.roc_auc_score(Y_test,  predictions_RF)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8696f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable importance of the best model\n",
    "importances = RF.feature_importances_\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "plt.title('Feature Importance')\n",
    "plt.bar(range(X_train.shape[1]), importances, align='center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc8429",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = RF.feature_importances_\n",
    "importances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
